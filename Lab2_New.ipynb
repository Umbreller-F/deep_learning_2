{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import *\n",
    "from utils import *\n",
    "from config import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../\\.data/imdb\"\n",
    "imdb_reviews = IMDBMovieReviews(path)\n",
    "train_data, test_data = imdb_reviews.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = imdb_reviews.split_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in (train_data, dev_data, test_data):\n",
    "    imdb_reviews.tokenize(data, max_seq_len=MAX_SEQ_LEN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"../\\.vector_cache/glove.6B.100d.txt\"\n",
    "glove = GloVeWordEmbeddings(glove_path, int((glove_path.split(\".\")[-2]).split(\"d\")[0]))\n",
    "token_to_index_mapping = imdb_reviews.create_vocab(train_data, unk_threshold=UNK_THRESHOLD)\n",
    "token_to_glove_mapping = glove.get_token_to_embedding()\n",
    "indices_found, embedding_matrix = imdb_reviews.get_embeds(token_to_index_mapping, token_to_glove_mapping, glove.get_num_dims())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {\"neg\": 0, \"pos\": 1}\n",
    "for data in (train_data, dev_data, test_data):\n",
    "    imdb_reviews.apply_vocab(data, token_to_index_mapping)\n",
    "    imdb_reviews.apply_label_map(data, label_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = token_to_index_mapping[PAD]\n",
    "train_dataset = SentimentDataset(train_data, pad_idx)\n",
    "dev_dataset = SentimentDataset(dev_data, pad_idx)\n",
    "test_dataset = SentimentDataset(test_data, pad_idx)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn\n",
    ")\n",
    "dev_dataloader = DataLoader(\n",
    "    dev_dataset, batch_size=BATCH_SIZE, collate_fn=dev_dataset.collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, collate_fn=test_dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30590, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_labels, n_rnn_layers, pad_idx, embedding_matrix, freeze=True):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)# , padding_idx=pad_idx\n",
    "        # self.embedding.weight.requires_grad = False\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        \n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=n_rnn_layers,\n",
    "            batch_first=True, \n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # self.output = nn.Linear(hidden_dim, n_labels)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, 16*2)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16*2, n_labels)\n",
    "        # self.h = torch.zeros(1, BATCH_SIZE, hidden_dim).cuda()\n",
    "\n",
    "    def forward(self, text):\n",
    "        x = self.embedding(text)\n",
    "        a, x = self.rnn(x)\n",
    "        # print(a, x)\n",
    "        # print(x.shape)\n",
    "        output_f = x[-2, :, :]\n",
    "        output_b = x[-1, :, :]\n",
    "        x = torch.cat([output_f, output_b], dim=-1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_labels, pad_idx, embedding_matrix, freeze=True):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)# , padding_idx=pad_idx\n",
    "        # self.embedding.weight.requires_grad = False\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=2,\n",
    "            batch_first=True, \n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # self.output = nn.Linear(hidden_dim, n_labels)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, 16*2)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16*2, n_labels)\n",
    "        # self.h = torch.zeros(1, BATCH_SIZE, hidden_dim).cuda()\n",
    "\n",
    "    def forward(self, text):\n",
    "        x = self.embedding(text)\n",
    "        a, (x, _) = self.lstm(x)\n",
    "        # print(a, x)\n",
    "        # print(x.shape)\n",
    "        output_f = x[-2, :, :]\n",
    "        output_b = x[-1, :, :]\n",
    "        x = torch.cat([output_f, output_b], dim=-1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_labels, pad_idx, embedding_matrix, freeze=True):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)# , padding_idx=pad_idx\n",
    "        # self.embedding.weight.requires_grad = False\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=2,\n",
    "            batch_first=True, \n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # self.output = nn.Linear(hidden_dim, n_labels)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, 16*2)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16*2, n_labels)\n",
    "        # self.h = torch.zeros(1, BATCH_SIZE, hidden_dim).cuda()\n",
    "\n",
    "    def forward(self, text):\n",
    "        x = self.embedding(text)\n",
    "        a, x = self.gru(x)\n",
    "        # print(a, x)\n",
    "        # print(x.shape)\n",
    "        # x = torch.cat([output_f, output_b], dim=-1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn1 = RNN(vocab_size=embedding_matrix.shape[0], embedding_dim=100, hidden_dim=256, n_labels=2, n_rnn_layers=1, \n",
    "#             pad_idx=pad_idx, embedding_matrix=embedding_matrix)\n",
    "\n",
    "# rnn2 = RNN(vocab_size=embedding_matrix.shape[0], embedding_dim=100, hidden_dim=256, n_labels=2, n_rnn_layers=2, \n",
    "#             pad_idx=pad_idx, embedding_matrix=embedding_matrix)\n",
    "\n",
    "# lstm = LSTM(vocab_size=embedding_matrix.shape[0], embedding_dim=100, hidden_dim=256, n_labels=2, \n",
    "#             pad_idx=pad_idx, embedding_matrix=embedding_matrix)\n",
    "\n",
    "model = LSTM(vocab_size=embedding_matrix.shape[0], embedding_dim=100, hidden_dim=256, n_labels=2, \n",
    "            pad_idx=pad_idx, embedding_matrix=embedding_matrix)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = rnn2\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fbace610c9d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# print(out.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for epoch in range(N_EPOCHS):\n",
    "#     pass\n",
    "# h0 = torch.zeros(1, BATCH_SIZE, 100)\n",
    "def fit(model, epochs):\n",
    "    correct_train=0\n",
    "    num_train=0\n",
    "    ac_train=[]\n",
    "    ac_validate=[]\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        correct_train=0\n",
    "        num_train=0\n",
    "        print('epoch:{}'.format(epoch))\n",
    "        for batch, (X, Y)  in enumerate(train_dataloader):\n",
    "            # torch.cuda.empty_cache()\n",
    "            # print('batch:{}'.format(batch))\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            # print(X.shape,Y.shape)\n",
    "            # if X.shape[0]<128:\n",
    "            #     print('not enough!')\n",
    "            #     break\n",
    "            num_train+=X.shape[0]\n",
    "            # print(torch.unsqueeze(X, dim=0).shape)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            out = torch.squeeze(out)\n",
    "            \n",
    "            # print(out.shape, Y.shape)\n",
    "            # print(torch.squeeze(out).shape)\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = out.argmax(dim=1)\n",
    "            # print(pred)\n",
    "\n",
    "            correct_train+=pred.eq(Y).sum()\n",
    "        scheduler.step()\n",
    "        ac_train.append(float(correct_train)/float(num_train))\n",
    "\n",
    "        model.eval()\n",
    "        correct_validate=0\n",
    "        num_validate=0\n",
    "        with torch.no_grad():\n",
    "            for batch, (X, Y)  in enumerate(dev_dataloader):\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                num_validate+=X.shape[0]\n",
    "                out = model(X)\n",
    "                out = torch.squeeze(out)\n",
    "                pred = out.argmax(dim=1)\n",
    "                # print(pred)\n",
    "\n",
    "                correct_validate+=pred.eq(Y).sum()\n",
    "                loss = criterion(out, Y)\n",
    "                # optimizer.step()\n",
    "\n",
    "        ac_validate.append(float(correct_validate)/float(num_validate))\n",
    "    \n",
    "    return ac_train, ac_validate\n",
    "\n",
    "# ac=float(correct)/float(num_train)\n",
    "# print('ac:{}'.format(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(ac_train)\n",
    "plt.plot(ac_validate)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(('Training', 'Validation'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ac_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ac_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'验证集测试'\n",
    "correct_validate=0\n",
    "num_validate=0\n",
    "ac_validate=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y)  in enumerate(dev_dataloader):\n",
    "        X = X.cuda()\n",
    "        Y = Y.cuda()\n",
    "        num_validate+=X.shape[0]\n",
    "        out = model(X)\n",
    "        out = torch.squeeze(out)\n",
    "        pred = out.argmax(dim=1)\n",
    "        # print(pred)\n",
    "\n",
    "        correct_validate+=pred.eq(Y).sum()\n",
    "        loss = criterion(out, Y)\n",
    "        # optimizer.step()\n",
    "print(float(correct_validate)/float(num_validate))\n",
    "# ac_validate.append(float(correct_validate)/float(num_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'lstm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'lstm.pkl'\n",
    "model_copy = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'测试集'\n",
    "def test(model_to_test):\n",
    "    correct_test=0\n",
    "    num_test=0\n",
    "    # ac_validate=[]\n",
    "    model_to_test.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y)  in enumerate(test_dataloader):\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            num_test+=X.shape[0]\n",
    "            out = model_to_test(X)\n",
    "            out = torch.squeeze(out)\n",
    "            pred = out.argmax(dim=1)\n",
    "            # print(pred)\n",
    "\n",
    "            correct_test+=pred.eq(Y).sum()\n",
    "            loss = criterion(out, Y)\n",
    "            # optimizer.step()\n",
    "    print(float(correct_test)/float(num_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
